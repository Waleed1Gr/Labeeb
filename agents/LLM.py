import os
import time
import faiss
import json
import numpy as np
from datetime import datetime, timedelta
from sentence_transformers import SentenceTransformer
from openai import OpenAI
import re

# Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ†
DATA_TASKS_FILE = "tasks.json"
DATA_INDEX_FILE = "tasks.index"

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª OpenAI
# client = OpenAI(api_key="")  # Ø¶Ø¹ Ù…ÙØªØ§Ø­ API Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù‡Ù†Ø§
# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø§Ø¨ÙŠØ±
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
dimension = 384

# Ø§Ù„Ù…Ù‡Ø§Ù… ÙˆØ§Ù„Ù€ FAISS
tasks = []
embeddings = []
index = faiss.IndexFlatL2(dimension)

# âœ… Ø¯Ø§Ù„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
def parse_date_arabic(text):
    text = text.strip().lower()
    now = datetime.now()

    if "Ø§Ù„ÙŠÙˆÙ…" in text:
        return now
    elif "Ø¨ÙƒØ±Ø©" in text:
        return now + timedelta(days=1)
    elif "Ø¨Ø¹Ø¯ Ø¨ÙƒØ±Ø©" in text:
        return now + timedelta(days=2)
    elif "Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹" in text:
        days_until_friday = (4 - now.weekday()) % 7
        return now + timedelta(days=days_until_friday)
    elif match := re.search(r"(Ø§Ù„)?(Ø¬Ù…Ø¹Ø©|Ø³Ø¨Øª|Ø£Ø­Ø¯|Ø§Ø«Ù†ÙŠÙ†|Ø«Ù„Ø§Ø«Ø§Ø¡|Ø§Ø±Ø¨Ø¹Ø§Ø¡|Ø®Ù…ÙŠØ³)( Ø§Ù„Ø¬Ø§ÙŠØ©)?", text):
        weekdays = {
            "Ø³Ø¨Øª": 5, "Ø£Ø­Ø¯": 6, "Ø§Ø«Ù†ÙŠÙ†": 0, "Ø«Ù„Ø§Ø«Ø§Ø¡": 1,
            "Ø§Ø±Ø¨Ø¹Ø§Ø¡": 2, "Ø®Ù…ÙŠØ³": 3, "Ø¬Ù…Ø¹Ø©": 4
        }
        target = weekdays[match.group(2)]
        delta = (target - now.weekday()) % 7
        delta = 7 if delta == 0 else delta
        return now + timedelta(days=delta)
    elif match := re.search(r"(\d{1,2}) (ÙŠÙ†Ø§ÙŠØ±|ÙØ¨Ø±Ø§ÙŠØ±|Ù…Ø§Ø±Ø³|Ø§Ø¨Ø±ÙŠÙ„|Ù…Ø§ÙŠÙˆ|ÙŠÙˆÙ†ÙŠÙˆ|ÙŠÙˆÙ„ÙŠÙˆ|Ø£ØºØ³Ø·Ø³|Ø³Ø¨ØªÙ…Ø¨Ø±|Ø§ÙƒØªÙˆØ¨Ø±|Ù†ÙˆÙÙ…Ø¨Ø±|Ø¯ÙŠØ³Ù…Ø¨Ø±)", text):
        day = int(match.group(1))
        month_map = {
            "ÙŠÙ†Ø§ÙŠØ±": 1, "ÙØ¨Ø±Ø§ÙŠØ±": 2, "Ù…Ø§Ø±Ø³": 3, "Ø§Ø¨Ø±ÙŠÙ„": 4, "Ù…Ø§ÙŠÙˆ": 5,
            "ÙŠÙˆÙ†ÙŠÙˆ": 6, "ÙŠÙˆÙ„ÙŠÙˆ": 7, "Ø£ØºØ³Ø·Ø³": 8, "Ø³Ø¨ØªÙ…Ø¨Ø±": 9, "Ø§ÙƒØªÙˆØ¨Ø±": 10,
            "Ù†ÙˆÙÙ…Ø¨Ø±": 11, "Ø¯ÙŠØ³Ù…Ø¨Ø±": 12
        }
        month = month_map[match.group(2)]
        year = now.year
        dt = datetime(year, month, day)
        if dt < now:
            dt = datetime(year + 1, month, day)
        return dt
    elif match := re.search(r"Ø§Ù„Ø³Ø§Ø¹Ø© (\d{1,2})([:Ù«ØŒ](\d{1,2}))?", text):
        hour = int(match.group(1))
        minute = int(match.group(3)) if match.group(3) else 0
        return now.replace(hour=hour, minute=minute, second=0, microsecond=0)

    return None

# ØªØ®Ø²ÙŠÙ† ÙˆØ§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ù‡Ø§Ù…
def save_tasks():
    tasks_serializable = [
        {"text": t["text"], "time": t["time"].isoformat()} for t in tasks
    ]
    with open(DATA_TASKS_FILE, "w", encoding="utf-8") as f:
        json.dump(tasks_serializable, f, ensure_ascii=False, indent=2)

def load_tasks():
    global tasks, embeddings, index
    if os.path.exists(DATA_TASKS_FILE):
        with open(DATA_TASKS_FILE, "r", encoding="utf-8") as f:
            loaded = json.load(f)
        tasks = []
        embeddings.clear()
        index.reset()
        for t in loaded:
            dt = datetime.fromisoformat(t["time"])
            tasks.append({"text": t["text"], "time": dt})
            emb = model.encode([t["text"]])[0]
            embeddings.append(emb)
        if embeddings:
            index.add(np.array(embeddings))

def save_index():
    faiss.write_index(index, DATA_INDEX_FILE)

def load_index():
    global index
    if os.path.exists(DATA_INDEX_FILE):
        index = faiss.read_index(DATA_INDEX_FILE)
    else:
        index = faiss.IndexFlatL2(dimension)

# âœ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©
def add_task(text):
    dt = parse_date_arabic(text)
    if dt is None:
        dt = datetime.now()

    emb = model.encode([text])[0]
    tasks.append({"text": text, "time": dt})
    embeddings.append(emb)
    index.add(np.array([emb]))
    save_tasks()
    save_index()
    print(f"âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ø¹ Ø§Ù„ØªØ§Ø±ÙŠØ®: {dt.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"    Ù†Øµ Ø§Ù„Ù…Ù‡Ù…Ø©: {text}")

# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù‡Ø§Ù…
def search_tasks(query, k=5):
    dt = parse_date_arabic(query)
    if dt:
        filtered = [t for t in tasks if abs((t["time"].date() - dt.date()).days) <= 1]
        if filtered:
            return filtered

    if not tasks:
        return []

    q_emb = model.encode([query])[0]
    _, I = index.search(np.array([q_emb]), k)
    return [tasks[i] for i in I[0]]

# ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
def classify_input(user_input):
    prompt = f"""Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù‚Ø§Ù„ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©: "{user_input}"

Ù‡Ù„ Ù‡Ø°Ø§ Ø·Ù„Ø¨:
- ØªØ³Ø¬ÙŠÙ„ Ù…Ù‡Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø©ØŸ (Ø£Ø¬Ø¨: ØªØ³Ø¬ÙŠÙ„)
- ØªØ°ÙƒÙŠØ±/Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù† Ø§Ù„Ù…Ù‡Ø§Ù…ØŸ (Ø£Ø¬Ø¨: ØªØ°ÙƒÙŠØ±)
- Ø£Ùˆ Ø´ÙŠØ¡ Ø«Ø§Ù†ÙŠØŸ (Ø£Ø¬Ø¨: ØºÙŠØ±)

Ø±Ø¯ Ø¨ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·: ØªØ³Ø¬ÙŠÙ„ Ø£Ùˆ ØªØ°ÙƒÙŠØ± Ø£Ùˆ ØºÙŠØ±.
"""
    res = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    return res.choices[0].message.content.strip()

# Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
def chat(user_input, related_tasks):
    if related_tasks:
        context = "\n".join([f"- {t['text']} (Ù…ÙˆØ¹Ø¯: {t['time'].strftime('%Y-%m-%d %H:%M')})" for t in related_tasks])
    else:
        context = "ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ Ø¹Ù†Ø¯Ùƒ Ø´ÙŠØ¡ Ù…Ø³Ø¬Ù„."

    prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø´Ø®ØµÙŠ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©.

- ÙƒÙ„Ø§Ù…Ùƒ Ù…Ø®ØªØµØ± Ø¨Ø³ ÙÙŠÙ‡ Ø·Ø±Ø§ÙØ© ÙˆØ®ÙØ© Ø¯Ù….
- ØªØ±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©.   
- Ù„Ø§ ØªÙƒØ«Ø± ÙƒÙ„Ø§Ù…ØŒ Ø¨Ø³ ØªÙƒÙÙŠÙƒ Ø¬Ù…Ù„ØªÙŠÙ† Ø£Ùˆ Ø«Ù„Ø§Ø«.
Ø§Ù„Ù…Ù‡Ø§Ù… Ù‡Ø°ÙŠ:

{context}

Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù‚Ø§Ù„: {user_input}
Ø±Ø¯ Ø¹Ù„ÙŠÙ‡ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ùˆ Ø§Ù…Ø²Ø­ Ø´ÙˆÙŠØŒ Ù„Ø§ ØªØ·ÙˆÙ„ Ø¨Ø§Ù„ÙƒÙ„Ø§Ù…."""
    
    res = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.6
    )
    return res.choices[0].message.content.strip()
# Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ù† Ù…Ù„Ù STT
def watch_file(file_path):
    print("ğŸ¤ Ø¬Ø§Ù‡Ø² Ù„Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø£ÙˆØ§Ù…Ø± STT Ù…Ù† Ø§Ù„Ù…Ù„Ù...")
    last_text = ""
    load_tasks()
    load_index()

    while True:
        if os.path.exists(file_path):
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read().strip()
            if text and text != last_text:
                print(f"\nğŸ“¥ Ù…Ø¯Ø®Ù„ STT: {text}")
                last_text = text

                intent = classify_input(text)
                if intent == "ØªØ³Ø¬ÙŠÙ„":
                    add_task(text)
                elif intent == "ØªØ°ÙƒÙŠØ±":
                    related = search_tasks(text)
                    reply = chat(text, related)
                    print("ğŸ¤–:", reply)
                else:
                    print("â— Ù…Ø§ ÙÙ‡Ù…Øª Ø§Ù„Ø£Ù…Ø±ØŒ Ø­Ø§ÙˆÙ„ ØªØ¹ÙŠØ¯ ØµÙŠØ§ØºØ© Ø·Ù„Ø¨Ùƒ.")
        time.sleep(1)

if __name__ == "__main__":
    watch_file("stt_output.txt")
