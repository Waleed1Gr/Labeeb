# main.py

from dotenv import load_dotenv
load_dotenv()

import os
import time
import threading
from pathlib import Path

import cv2
import time
from utils.audio import record_until_silence_fixed
from utils.fuzzy_wakeword import wait_for_wake_word
from api_clients.stt_api import transcribe_from_file
from api_clients.llm_api import classify_input, chat_response
from api_clients.tts_api import speak, speak_warning
from api_clients.vision_api import detect_objects

# â”€â”€â”€ Import the Okaz RSS functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from api_clients.news_api import fetch_okaz_headlines, summarize_headlines

from utils.task_handler import (
    load_tasks,
    add_task,
    delete_task,
    search_tasks,
    save_tasks,
    tasks,
    embeddings,
    index,
    create_index,
    clear_all_tasks
)

SESSION_TIMEOUT = 60
session_active = False
last_interaction = 0

import wave
import audioop

SESSION_TIMEOUT = 60
session_active = False
last_interaction = 0

def current_time():
    return time.time()

def phone_person_detector():
    """
    Continuously monitors webcam frames for a phone being held by a person.
    If a phone overlaps with a person for 10+ seconds, gives a spoken warning.
    This runs in a background thread, independent of wake word.
    """
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("âŒ Camera not available; vision disabled.")
        return

    print("ğŸ“· Vision thread started (local YOLO)")

    phone_timer_start = 0
    warning_issued = False

    while True:
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.1)
            continue

        detections = detect_objects(frame)
        people_boxes = detections.get("people", [])
        phone_boxes = detections.get("phones", [])

        # print(f"ğŸ” Detected {len(people_boxes)} people, {len(phone_boxes)} phones")

        # Check for overlap: is any phone inside a person box?
        overlap = False
        for (fx1, fy1, fx2, fy2) in phone_boxes:
            phone_cx = (fx1 + fx2) // 2
            phone_cy = (fy1 + fy2) // 2
            for (px1, py1, px2, py2) in people_boxes:
                if px1 < phone_cx < px2 and py1 < phone_cy < py2:
                    overlap = True
                    break
            if overlap:
                break

        if overlap:
            if phone_timer_start == 0:
                phone_timer_start = time.time()
                print("â±ï¸ Started phone timer")

            elapsed = time.time() - phone_timer_start
            # print(f"â±ï¸ Phone overlap duration: {elapsed:.1f}s")

            if elapsed >= 10.0 and not warning_issued:
                print("ğŸ“¢ Warning issued: phone held over 10 seconds")
                speak_warning("Ù„Ùˆ Ø³Ù…Ø­Øª Ù„Ø§ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¬ÙˆØ§Ù„ ÙÙŠ Ø§Ù„Ø´ØºÙ„")
                warning_issued = True
        else:
            if phone_timer_start != 0:
                print("ğŸ”„ Overlap ended; resetting phone timer")
            phone_timer_start = 0
            warning_issued = False

        # Slight sleep to reduce CPU load
        time.sleep(0.1)
def current_time():
    return time.time()

# ğŸ™ï¸ Main STT handler
def record_and_transcribe(wait_for_wake: bool = True) -> str:
    global session_active, last_interaction

    if wait_for_wake and not session_active:
        if not wait_for_wake_word():
            return ""
        session_active = True
        last_interaction = current_time()

    filename = Path(f"record_{int(time.time())}.wav")

    try:
        print("ğŸ™ï¸ Recording audio...")
        success = record_until_silence_fixed(
            filename,
            sample_rate=16000,
            silence_duration=2,
            max_duration=10
        )

        if not success:
            print("âš ï¸ No speech detected.")
            return ""

        # ğŸ§  Transcribe
        text = transcribe_from_file(
            filename,
            language="ar",
            prompt="ØªÙˆÙ‚Ø¹ ÙƒÙ„Ø§Ù… Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©"
        )

        # Clean up the audio file
        try:
            filename.unlink()
        except:
            pass

        # ğŸ§¹ Check STT junk
        junk_phrases = {"Ø§Ù‡", "Ø§Ù…", "Ù…Ù…", "Ø§Ø§", "Ù…Ù…Ù…Ù…", "Ø§Ù‡Ù…", "Ø§Ø§Ø§Ø§", ""}
        if not text or text.strip() in junk_phrases:
            print("ğŸ§¹ Junk or empty phrase â€” skipping.")
            return ""

        print("ğŸ“„ Transcribed text:", text)

        # â³ Update session activity
        last_interaction = current_time()

        if session_active and (current_time() - last_interaction > SESSION_TIMEOUT):
            session_active = False
            print("ğŸ’¤ Session timed out.")
            speak("ØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©ØŒ Ù†Ø§Ø¯ÙŠÙ†ÙŠ Ø¥Ø°Ø§ Ø§Ø­ØªØ¬ØªÙ†ÙŠ!")

        return text.strip()

    except Exception as e:
        print(f"âŒ Error during recording/transcription: {e}")
        return ""

def main():
    global session_active, index, embeddings, tasks
    print("ğŸ”° Loading tasks...")
    load_tasks()

    # Start vision thread
    cam_thread = threading.Thread(target=phone_person_detector, daemon=True)
    cam_thread.start()

    print("ğŸš€ Assistant is up and running!")

    while True:
        try:
            user_input = record_and_transcribe(wait_for_wake=not session_active)
            if not user_input:
                if session_active:
                    session_active = False
                    print("\nğŸ’¤ Session ended.")
                    speak("ØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©ØŒ Ù†Ø§Ø¯ÙŠÙ†ÙŠ Ø¥Ø°Ø§ Ø§Ø­ØªØ¬ØªÙ†ÙŠ!")
                continue

            lower = user_input.strip().lower()

            # ğŸ” Optional: keyword override for Ø­Ø°Ù Ø§Ù„ÙƒÙ„
            if "Ø§Ø­Ø°Ù ÙƒÙ„" in lower or "Ø§Ø­Ø°Ù Ø§Ù„Ù…Ù‡Ø§Ù… ÙƒÙ„Ù‡Ø§" in lower:
                intent = "Ø­Ø°Ù_Ø§Ù„ÙƒÙ„"
            else:
                intent = classify_input(user_input)

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Intent: Delete All Tasks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if intent == "Ø­Ø°Ù_Ø§Ù„ÙƒÙ„":
                speak("Ù…ØªØ£ÙƒØ¯ ØªØ¨ÙŠÙ†ÙŠ Ø£Ø­Ø°Ù ÙƒÙ„ Ø§Ù„Ù…Ù‡Ø§Ù…ØŸ Ù‚Ù„ Ù†Ø¹Ù… Ø£Ùˆ Ù„Ø§.")
                confirmation = ""
                while confirmation not in ["Ù†Ø¹Ù…", "Ù„Ø§"]:
                    confirmation = record_and_transcribe(wait_for_wake=False).strip().lower()

                if confirmation == "Ù†Ø¹Ù…":
                    clear_all_tasks()
                    speak("ØªÙ…Ø§Ù…ØŒ Ù…Ø³Ø­Øª ÙƒÙ„ Ø§Ù„Ù…Ù‡Ø§Ù….")
                else:
                    speak("Ù…Ø§ ØµØ§Ø± Ø´ÙŠØ¡ØŒ Ù…Ø§ Ù…Ø³Ø­Øª ÙˆÙ„Ø§ Ù…Ù‡Ù…Ø©.")
                continue

            elif intent == "Ø­Ø°Ù":
                delete_task(user_input)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Other intents â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            elif intent == "ØªØ³Ø¬ÙŠÙ„":
                add_task(user_input)

            elif intent == "ØªØ°ÙƒÙŠØ±":
                related = search_tasks(user_input)
                if not related:
                    if tasks:
                        all_texts = "ØŒ ".join([t["text"] for t in tasks])
                        speak(f"Ù…Ù‡Ø§Ù…Ùƒ Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù‡ÙŠ: {all_texts}")
                    else:
                        speak("Ù…Ø§ Ø¹Ù†Ø¯Ùƒ Ù…Ù‡Ø§Ù… Ù…Ø³Ø¬Ù„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.")
                else:
                    response = chat_response(user_input, related)
                    print("ğŸ¤–", response)
                    speak(response)
                    if "<close_conversation>" in response:
                        session_active = False
                        print("ğŸ”Š Waiting for wake word: 'Ù„Ø¨ÙŠØ¨'...")
                        continue

            elif intent == "Ø­Ø°Ù":
                delete_task(user_input)

            else:
                response = chat_response(user_input, [])
                print("ğŸ¤–", response)
                speak(response)
                if "<close_conversation>" in response:
                    session_active = False
                    print("ğŸ”Š Waiting for wake word: 'Ù„Ø¨ÙŠØ¨'...")
                    continue

        except KeyboardInterrupt:
            print("\nğŸ›‘ Shutting down...")
            break
        except Exception as e:
            print(f"Main loop error: {e}")
            speak("Ø­ØµÙ„ Ø®Ø·Ø£ØŒ Ø¨Ø³ Ø±Ø§Ø­ Ø£ÙƒÙ…Ù„ Ø´ØºÙ„")


if __name__ == "__main__":
    main()
